title: 私有集群 
date: 2023-10-31 15:58:16 
tags: []
categories: [集群]
password: 7FKBKZrTTTPG2LnC

---
 <!--more-->
9 @(私有集群的搭建)
###私有集群搭建
一、服务器的准备
* 阿里云实例（115.29.97.126）
* 华为云实例（114.115.203.81）
* 阿里云实例2(115.29.35.125）
* 本机实例（）
1.1）服务器环境设置
修改服务器hostname
* 阿里（wqkenqing）
* 华为（wqkenqing02）
* 阿里2(wqkenqing03)
* 虚拟机（wqkneqing04）
[hostname修改教程](http://blog.csdn.net/huangxy10/article/details/40213095)
***
1.2）配置语言环境（取的默认环境）
![Alt text](./1475308903359.png)
1.3）[关闭防火墙](https://my.oschina.net/cjun/blog/344836)
1.4）创建hadoop用户
1.5）上传相关文件(jdk1.7、hadoop2.7.2)
***
1.6）配置环境变量
**
export JAVA_HOME=/usr/local/jdk1.7
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib

export PATH=${JAVA_HOME}/bin:$PATH **
***
1.7）配置免密码登陆
	1)实现本机ssh免秘钥登录：
* $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
* $ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
* chmod 700 ~/.ssh/authorized_keys
***
2)实现集群ssh免秘钥登录
+ 写入每一个集群机器秘钥到主NN 的authorized_keys中 ssh hadoopXXX 'cat /home/hadoop/.ssh/id_dsa.pub' >> ~/.ssh/authorized_keys
+  覆盖所有集群机器authorized_keys：scp ~/.ssh/authorized_keys hadoopXXX:/home/hadoop/.ssh/authorized_keys

二、hadoop配置
2.1）配置hadoop环境
export HADOOP_HOME=/usr/local/hadoop/hadoop

export HIVE_HOME=/usr/local/hadoop/hive

export HBASE_HOME=/usr/local/hadoop/hbase

PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HBASE_HOME/bin:$HIVE_HOME/bin
***
hadoop配置文件配置
2.1）wqkenqing节点（以后作为name节点）
**修改 /home/hadoop/etc/hadoop/ core-site.xml**
在 <configuration> 块儿中添加：

<property>

<name>fs.defaultFS</name>

<value>hdfs://wqkenqing.com:9000</value>

</property>

<property>

<name>hadoop.tmp.dir</name>

<value>file:/home/hadoop/tmp</value>

</property>

<property>

<name>io.file.buffer.size</name>

<value>131702</value>

<!-- 指定zookeeper地址 -->  
    <property>  
        <name>ha.zookeeper.quorum</name>  
        <value>wqkenqing.com:2181,wqkenqing02.com:2181</value>  
    </property>  
</property>
***
**修改 /home/hadoop/etc/hadoop/ hdfs-site.xml**
在 <configuration> 块儿中添加：

<property>

<name>dfs.namenode.name.dir</name>

<value>file:/home/hadoop/hdfs/name</value>

</property>

<property>

<name>dfs.datanode.data.dir</name>

<value>file:/home/hadoop/hdfs/data</value>

</property>

<property>

<name>dfs.replication</name>

<value>2</value>

</property>

<property>

<name>dfs.namenode.secondary.http-address</name>

<value>wqkenqing.com:9001</value>

</property>

<property>

<name>dfs.webhdfs.enabled</name>

<value>true</value>
</property>
***
 <!--指定hdfs的nameservice为mycluster，需要和core-site.xml中的保持一致 -->  
    <property>  
        <name>dfs.nameservices</name>  
        <value>wqkenqing.com</value>  
    </property>  

    <!-- mycluster下面有两个NameNode，分别是nn1，nn2 -->  
    <property>  
     <name>dfs.ha.namenodes.mycluster</name>  
        <value>wqkenqing,wqkenqing02</value>  
    </property>  

    <!-- nn1的RPC通信地址 -->  
    <property>  
        <name>dfs.namenode.rpc-address.mycluster.nn1</name>  
        <value>wqkenqing:9000</value>  
    </property>  

    <!-- nn1的http通信地址 -->  
    <property>  
        <name>dfs.namenode.http-address.mycluster.nn1</name>  
        <value>h1m1:50070</value>  
    </property>  

    <!-- nn2的RPC通信地址 -->  
    <property>  
        <name>dfs.namenode.rpc-address.mycluster.nn2</name>  
        <value>wqkenqing02:9000</value>  
    </property>  

    <!-- nn2的http通信地址 -->  
    <property>  
        <name>dfs.namenode.http-address.mycluster.nn2</name>  
        <value>wqkenqing02:50070</value>  
    </property>  

    <!-- 指定NameNode的元数据在JournalNode上的存放位置 -->  
    <property>  
        <name>dfs.namenode.shared.edits.dir</name>  
        <value>qjournal://wqkenqing:8485;wqkenqing02:8485/mycluster</value>  
    </property>  

    <!-- 指定JournalNode在本地磁盘存放数据的位置 -->  
    <property>  
        <name>dfs.journalnode.edits.dir</name>  
        <value>/usr/lib/hadoop/journal</value>  
    </property>  

    <!-- 开启NameNode失败自动切换 -->  
    <property>  
        <name>dfs.ha.automatic-failover.enabled</name>  
        <value>true</value>  
    </property>  

    <!-- 配置失败自动切换实现方式 -->  
    <property>  
        <name>dfs.client.failover.proxy.provider.mycluster</name>  
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>  
    </property>  

    <!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行-->  
    <property>  
        <name>dfs.ha.fencing.methods</name>  
        <value>  
            sshfence  
            shell(/bin/true)  
        </value>  
    </property>  

    <!-- 使用sshfence隔离机制时需要ssh免登陆 -->  
    <property>  
        <name>dfs.ha.fencing.ssh.private-key-files</name>  
        <value>/home/hadoop/.ssh/id_rsa</value>  
    </property>  

    <!-- 配置sshfence隔离机制超时时间 -->  
    <property>  
        <name>dfs.ha.fencing.ssh.connect-timeout</name>  
        <value>30000</value>  
    </property>
***
**修改 /home/hadoop/etc/hadoop/ mapred-site.xml**
这个文件默认不存在，需要从 mapred-site.xml.template 复制过来
在 <configuration> 块儿中添加：

<property>

<name>mapreduce.framework.name</name>

<value>yarn</value>

</property>

<property>

<name>mapreduce.jobhistory.address</name>

<value>wqkenqing:10020</value>

</property>

<property>

<name>mapreduce.jobhistory.webapp.address</name>

<value>wqkenqing:19888</value>

</property>
***
**修改 /home/hadoop/etc/hadoop/ yarn-site.xml**
在 <configuration> 块儿中添加：

<property>

<name>yarn.nodemanager.aux-services</name>

<value>mapreduce_shuffle</value>

</property>

<property>

<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>

<value>org.apache.hadoop.mapred.ShuffleHandler</value>

</property>

<property>

<name>yarn.resourcemanager.address</name>

<value>wqkenqing:8032</value>

</property>

<property>

<name>yarn.resourcemanager.scheduler.address</name>

<value>wqkenqing:8030</value>

</property>

<property>

<name>yarn.resourcemanager.resource-tracker.address</name>

<value>wqkenqing:8031</value>

</property>

<property>

<name>yarn.resourcemanager.admin.address</name>

<value>wqkenqing:8033</value>

</property>

<property>

<name>yarn.resourcemanager.webapp.address</name>

<value>wqkenqing:8088</value>

</property>
***
**修改 /home/hadoop/etc/hadoop/ slaves**

删除已有内容，添加：
wqkenqing02（data节点）

***
http://115.29.97.126:50070/
***
**启动 hadoop**
在master启动hadoop，从节点会自动启动
**初始化**
	hadoop-daemon.sh start journalnode
$ hdfs namenode -format
$ hadoop-daemon.sh start namenode
$ hadoop-daemon.sh start datanode
$ start-dfs.sh
$ start-yarn.sh
***
启动报错
**java.io.IOException: All specified directories are failed to load.**
解决方式：配置文件中的地址书写有问题
***
至此hadoop集群中的关键功能已经实现
* hdfs
* mapreudce
[集群配置参考文献](http://www.tuicool.com/articles/uAnyEfj)
***
hadoop220集群运行状态：
![Alt text](./1475419804382.png)

[同步时钟参考文献](http://f.dataguru.cn/thread-475940-1-1.html)
###hbase集成(尚未完成)
* [hadoop集群搭建参考文献](http://www.linuxidc.com/Linux/2013-06/86347p4.htm)
*

***
###hbase集群启动指令
* start-hbase.sh
* [hbase中的zookeeper使用教程](http://blog.csdn.net/korder/article/details/47403801)

###集群重置
* hadoop配置完成(ali1+ali2)
* 添加hbase

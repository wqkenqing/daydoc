

## hbase架构

架构如图：

![img](http://img.wqkenqing.ren/typora_img/1228818-20180402125111282-1966599087-20230821162317280.png)

![img](http://img.wqkenqing.ren/typora_img/1228818-20180402125111282-1966599087.png)

![img](http://img.wqkenqing.ren/typora_img/1228818-20180402130346713-706113248.png)



### hbase的组成

1. Client

   1. 客户端，后面以客户端视角进行读、写等操作的流程分析

2. ZooKeeper

   1. 一些元数据信息:包括有哪些 Table，每个 Table 有哪些 Column Family

   2. 协助HMaster选举，为 HBase 提供 Failover 机制，选举 Master，避免单点 Master 单点故障问题

   3. 实时监控 RegionServer 的状态，将 RegionServer 的上线和下线信息实时通知给 Master

   4. 存储所有 Region 的寻址入口：/hbase/meta-region-server

      

3. HMaster

   1. 为 RegionServer 分配 Region
   2. 负责 RegionServer 的负载均衡
   3. 发现失效的 RegionServer 并重新分配其上的 Region
   4. HDFS 上的垃圾文件（HBase）回收
   5. 处理 Schema 更新请求（表的创建，删除，修改，列簇的增加等等）

4. HRegionServer

   1. HRegion

      1. >  table在行的方向上分隔为多个Region。**Region是HBase中分布式存储和负载均衡的最小单元**，即不同的region可以分别在不同的Region Server上，但同一个Region是不会拆分到多个server上

      2. >  Region按大小分隔，每个表一般是只有一个region。随着数据不断插入表，region不断增大，当region的某个列族达到一个阈值时就会分成两个新的region。

      3. > 每个region由以下信息标识：< 表名,startRowkey,创建时间>

      4. 成员

         1. Store

            1. > 由一个或多个store组成，至少是一个store，hbase会把一起访问的数据放在一个store里面，即为每个 ColumnFamily建一个store，如果有几个ColumnFamily，也就有几个Store。一个Store由一个memStore和0或者 多个StoreFile组成。 HBase以store的大小来判断是否需要切分region

            2. 成员

               1. MemStore

                  1. > memStore 是放在内存里的。保存修改的数据即keyValues。当memStore的大小达到一个阀值（默认128MB）时，memStore会被flush到文 件，即生成一个快照。目前hbase 会有一个线程来负责memStore的flush操作。

               2. StoreFile

                  1. > memStore内存中的数据写到文件后就是StoreFile，StoreFile底层是以HFile的格式保存。当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、major compaction），在合并过程中会进行版本合并和删除工作（majar），形成更大的storefile。

                  2. 成员

                     1. HFile

                        1. > HBase中KeyValue数据的存储格式，HFile是Hadoop的 二进制格式文件，实际上StoreFile就是对Hfile做了轻量级包装，即StoreFile底层就是HFile。

   2. **.META.**

      1. 记录了用户所有表拆分出来的的 Region 映射信息，.META.可以有多个 Regoin
      2. 老版还有一个-ROOT-表，这里不缀述了，可以了解一下就行

   3. RegionServer 维护 Master 分配给它的 Region，处理对这些 Region 的 IO 请求

   4. RegionServer 负责 Split 在运行过程中变得过大的 Region，负责 Compact 操作

   5. client 访问 HBase 上数据的过程并不需要 master 参与（寻址访问 zookeeper 和 RegioneServer，数据读写访问 RegioneServer），Master 仅仅维护者 Table 和 Region 的元数据信息，负载很低。

   6. .META. 存的是所有的 Region 的位置信息，那么 RegioneServer 当中 Region 在进行分裂之后 的新产生的 Region，是由 Master 来决定发到哪个 RegioneServer，这就意味着，只有 Master 知道 new Region 的位置信息，所以，由 Master 来管理.META.这个表当中的数据的 CRUD

   7. 所以结合以上两点表明，在没有 Region 分裂的情况，Master 宕机一段时间是可以忍受的。

5. **HLog**

   1. > HLog(WAL log)：WAL意为write ahead log，用来做灾难恢复使用，HLog记录数据的所有变更，一旦region server 宕机，就可以从log中进行恢复。
      > HLog文件就是一个普通的Hadoop Sequence File， Sequence File的value是key时HLogKey对象，其中记录了写入数据的归属信息，除了table和region名字外，还同时包括sequence number和timestamp，timestamp是写入时间，sequence number的起始值为0，或者是最近一次存入文件系统中的sequence number。 Sequence File的value是HBase的KeyValue对象，即对应HFile中的KeyValue。

[hbase介绍](https://www.cnblogs.com/frankdeng/p/9310278.html)

[hbase组成介绍](https://www.cnblogs.com/frankdeng/p/9310278.html)


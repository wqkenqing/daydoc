```
#!/bin/bash

# 设定备份时间间隔为30秒
BACKUP_INTERVAL=30

# 设定保留备份文件的天数
RETAIN_DAYS=3

# 设定日志文件名
LOG_FILE="/data/log-bak/backup.log"

# 设定上次备份时间文件名
LAST_TIME_FILE="/data/log-bak/last_time.txt"

# 设定日志目录为当天的日期
LOG_DIR="/data/log-bak/$(date +%Y%m%d)"

if [ ! -d "$LOG_DIR" ]; then
  # 如果日志目录不存在，则创建该目录
  mkdir -p "$LOG_DIR"
fi

if [ ! -f "$LAST_TIME_FILE" ]; then
  # 如果上次备份时间文件不存在，则创建该文件，并写入当前时间和容器名
  touch "$LAST_TIME_FILE"
  for CONTAINER_NAME in $(docker ps --format "{{.Names}}"); do
    echo "$CONTAINER_NAME $(date +%s)" >> "$LAST_TIME_FILE"
  done
fi

while true; do
# **重新设定日志目录为当前日期**
   LOG_DIR="/data/log-bak/$(date +%Y%m%d)"

   if [ ! -d "$LOG_DIR" ]; then
     # 如果日志目录不存在，则创建该目录
     mkdir -p "$LOG_DIR"
   fi

  # 循环遍历docker中所有容器名和对应的容器ID
  for CONTAINER_NAME in $(docker ps --format "{{.Names}}"); do

    # 定义备份文件名
    LOG_BACKUP_FILE="${LOG_DIR}/${CONTAINER_NAME}.log"

    if [ ! -f "$LOG_BACKUP_FILE" ]; then
      # 如果备份文件不存在，则创建该文件
      touch "$LOG_BACKUP_FILE"
    fi

    # 从上次备份时间文件中读取对应容器的最后一次备份时间，并赋值给LAST_TIME变量
    LAST_TIME=$(grep "$CONTAINER_NAME" "$LAST_TIME_FILE" | tail -n 1 | cut -d ' ' -f 2)

    # 通过docker logs命令获取自上次备份时间以来新增的日志并追加到备份文件中
    docker logs --timestamps --since "$LAST_TIME" "$CONTAINER_NAME" >> "$LOG_BACKUP_FILE"
    # 向日志文件中写入备份的容器名和时间
    echo "[$(date)] Backed up $CONTAINER_NAME log to $LOG_BACKUP_FILE" >> "$LOG_FILE"
    # 更新上次备份时间为当前时间，并写入到上次备份时间文件中，附带容器名
    echo "$CONTAINER_NAME $(date +%s)" >> "$LAST_TIME_FILE"
  done

  # 删除过期的备份文件，只保留最近3天的备份文件，并向日志文件中写入删除的文件名和时间
  find /data/logs-bak/ -type d -mtime +$RETAIN_DAYS -delete -print | xargs -I {} echo "[$(date)] Deleted expired backup file {}" >> "$LOG_FILE"

  # 休眠备份时间间隔后继续下一轮备份
  sleep $BACKUP_INTERVAL
done

```





```
#!bin/sh

if [ ! -d "/data/logs-bak"  ];then
    mkdir "/data/logs-bak"
fi

d="$(date -d 'yesterday' +%Y-%m-%d)"

if [ ! -d "/data/logs-bak/$d"  ];then
    mkdir -p "/data/logs-bak/$d"
fi

cd /data/logs-bak/$d

for file in /var/lib/docker/containers/*
do
    if test -d $file
    then
        echo $file 是目录
        for logfile in $file/*.log
        do
            if test -f $logfile
            then
                echo $logfile 开始备份
                a="$(basename $logfile)"
                b="${a:0:12}"
                if [ ! -d $b  ];then
                    mkdir $b
                fi
                d="$(date -d 'yesterday' +%Y-%m-%d)"
                log_file="${b}_${d}.log"
                cp $logfile "${b}/$log_file"
                echo '' > $logfile
                tar -cvzf "${b}/${log_file}.tar.gz" "${b}/$log_file"
                rm "${b}/$log_file"
            fi
        done
    fi
done

cd /data/logs-bak 
tar -cvzf /data/logs-bak/$d.tar.gz /data/logs-bak/$d
```





```
#!bin/sh

if [ ! -d "/data/logs-bak"  ];then
    mkdir "/data/logs-bak"
fi

d="$(date -d 'yesterday' +%Y-%m-%d)"

if [ ! -d "/data/logs-bak/$d"  ];then
    mkdir -p "/data/logs-bak/$d"
fi

cd /data/logs-bak/$d

for file in /var/lib/docker/containers/*
do
    if test -d $file
    then
        echo $file 是目录
        for logfile in $file/*.log
        do
            if test -f $logfile
            then
                echo $logfile 开始备份
                a="$(basename $logfile)"
                b="${a:0:12}"
                if [ ! -d $b  ];then
                    mkdir $b
                fi
                d="$(date -d 'yesterday' +%Y-%m-%d)"
                log_file="${b}_${d}.log"
                cp $logfile "${b}/$log_file"
                echo '' > $logfile
            fi
        done
    fi
done

cd /data/logs-bak 
tar -cvzf $d.tar.gz $d
rm -rf $d
```



delete_log.sh



```
#!/bin/bash

# 指定日志目录
log_dir="/data/logs-bak"

# 计算三天前的日期（格式：YYYY-MM-DD）
three_days_ago=$(date -d '3 days ago' +%Y-%m-%d)

# 使用 find 命令查找超过三天的旧日志文件并删除
find "$log_dir" -name '*.tar.gz'  | while read -r log_file; do
    # 提取日志文件名中的日期部分（假定日志文件名格式为 YYYY-MM-DD.tar.gz）
    log_date=$(basename "$log_file" | cut -d'_' -f1)
    # 比较日志日期是否超过三天前的日期
    if [[ "$log_date" < "$three_days_ago" ]]; then
        echo "Deleting old log file: $log_file"
        rm "$log_file"
    fi
done

```

---



1. 接下来，每台服务器部署这个备份与删除的定时任务
2. 同步日志数据到日志服务器
3. 日志服务器保留一个月的数据。 
4. 将最新的数据上传至hdfs

---



sync_log_to_node.sh



```
#!/bin/bash 

nodes=datanode1,datanode2,datanode3

log_path=/data/logs-bak/
newest_log_file="$(date -d 'yesterday' +%Y-%m-%d)".tar.gz
hostname=$(hostname)

target_base_path=/data2/all-node-logs

## 进入日志文件夹路径
 cd  /data/logs-bak/
## 确认日志文件是否存在
if [ ! -f "/data/logs-bak/$d"  ];then
    echo $newest_log_file is not exst, please check!
fi

## 存在则将日志拷贝至nodes对应下面节点的目标地址 
for node in nodes
do 
scp $log_path/$newest_log_file $node:$target_base_path/$hostname/
echo "sync the log file to "$node
done 

## 每个路径下面保留30天的日志


## 检测最新日志是否存在，若存在则上传至hdfs对应路径下





```

```
 pssh -h app.txt "nohup  /opt/scripts/sync_log_to_node.sh &>> /data/nohup.out &"
```

```
 pssh -h app.txt "nohup  /opt/scripts/back-logs.sh &>> /data/nohup.out &"
```



```
#!/bin/bash

# 指定要处理的文件夹路径
target_dir="/path/to/your/folder"

# 切换到目标文件夹路径
cd "$target_dir" || exit

# 获取当前文件夹下的所有文件，并按照修改时间（mtime）降序排序
files=($(ls -t))

# 定义要保留的文件数目
keep_count=30

# 计算要删除的文件数目
delete_count=$(( ${#files[@]} - keep_count ))

# 如果文件数目超过要保留的数量，则删除旧文件
if [ "$delete_count" -gt 0 ]; then
    # 循环删除旧文件，直到保留最新的 keep_count 个文件
    for (( i=0; i<delete_count; i++ )); do
        file_to_delete="${files[$((keep_count + i))]}"
        echo "Deleting old file: $file_to_delete"
        rm -f "$file_to_delete"
    done
    echo "Deleted $delete_count old files."
else
    echo "No old files to delete."
fi

```



这个脚本主要的用处是来删除与管理*.tar.gz文件的个数

```
#!/bin/bash
# 指定日志目录
# 通过log_dir reatin_day两个参数管理要删除的日志目录
log_dir=$1
retain_day=$2
# 计算三天前的日期（格式：YYYY-MM-DD）
max_reatin_day=$(date -d "$retain_day days ago" +%Y-%m-%d)
# 使用 find 命令查找超过三天的旧日志文件并删除
find "$log_dir" -name '*.tar.gz'  | while read -r log_file; do
    # 提取日志文件名中的日期部分（假定日志文件名格式为 YYYY-MM-DD.tar.gz）
    log_date=$(basename "$log_file" | cut -d'_' -f1)
    # 比较日志日期是否超过三天前的日期
    if [[ "$log_date" < "$three_days_ago" ]]; then
        echo "Deleting old log file: $log_file"
        rm "$log_file"
    fi
done
```



需要写一个脚本来管理日志管理节点的内容

```
## 功能点 1. 遍历路径下面的内容，删除每个节点文件夹下对应超过数目的最旧文件
#!/bin/bash
target_path=$1
nodes=$（ls $taget_path)

for node in $nodes
do 
echo "begin to check "$target_path/$node
/bin/bash /opt/scripts/delete_log_file.sh  $target_path/$node 3
echo "=================================="
done 
```



crontab 文件管理

有两类，日志node节点会有所不同

普通节点备份、同步、删除

```
10 0  * * * /opt/scripts/back-logs.sh  >> /var/log/backup.log
20 0  * * * /opt/scripts/sync_log_to_node.sh  >> /var/log/sync_log.log
40 0  * * * /opt/scripts/delete_log_file.sh /data/logs-bak 7 >> /var/log/sync_log.log
```

日志管理节点 会多两个文件 1 集中存储30天日志管理

``` 
10 0  * * * /opt/scripts/back-logs.sh  >> /var/log/backup.log
20 0  * * * /opt/scripts/sync_log_to_node.sh  >> /var/log/sync_log.log
40 0  * * * /opt/scripts/delete_log_file.sh /data/logs-bak 7 >> /var/log/sync_log.log
10 1  * * * /opt/scripts/node_log_manage.sh /data2/all-node-logs 30 >> /var/log/log_manage.log
```



视频服务器的日志备份

/home/sunrise/log_backup/logs

~/Desktop/CarDetec20200520-2learingandrun/logs

/bin/bash backup_log.sh  /home/sunrise/log_backup/logs ~/Desktop/CarDetec20200520-2learingandrun/logs

```
#!bin/bash

backup_path=$1
target_path=$2

if [ ! -d  $backup_path  ];then
    mkdir $backup_path
fi

d="$(date -d 'yesterday' +%Y-%m-%d)"

if [ ! -d "$backup_path/$d"  ];then
    mkdir -p "$backup_path/$d"
fi

cd $backup_path/$d

for file in $target_path/*
do
   if test -d $file
    then
        echo $file 是目录
        for logfile in $file/*.log
        do
            if test -f $logfile
            then
                echo $logfile 开始备份
                a="$(basename $logfile)"
                b="${a:0:12}"
                if [ ! -d $b  ];then
                    mkdir $b
                fi
                d="$(date -d 'yesterday' +%Y-%m-%d)"
                log_file="${b}_${d}.log"
                cp $logfile "${b}/$log_file"
                echo '' > $logfile
            fi
        done
    fi
     if test -f $logfile
            then
                echo $logfile 开始备份
                a="$(basename $logfile)"
                b="${a:0:12}"
                if [ ! -d $b  ];then
                    mkdir $b
                fi
                d="$(date -d 'yesterday' +%Y-%m-%d)"
                log_file="${b}_${d}.log"
                cp $logfile "${b}/$log_file"
                echo '' > $logfile
      fi
done

cd $backup_path
tar -cvzf $backup_path/$d.tar.gz $d
rm -rf $d
```


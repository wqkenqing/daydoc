# 数据湖分享

##  1、什么是数据湖？

Wikipedia上说数据湖是一类存储数据自然/原始格式的系统或存储，通常是对象块或者文件， 包括原始系统所产生的原始数据拷贝以及为了各类任务而产生的转换数据， 

包括来自于

1. 关系型数据库中的结构化数据（行和列）
2. 半结构化数据（如CSV、日志、XML、JSON）
3. 非结构化数据（如email、文档、PDF等） 
4. 二进制数据（如图像、音频、视频）。

AWS定义数据湖是一个集中式存储库，允许您以任意规模存储所有结构化和非结构化数据。

### 1.1 数据湖需要满足什么条件？

1. 数据湖需要提供足够用的数据存储能力，这个存储保存了一个企业/组织中的所有数据。
2.  数据湖可以存储海量的任意类型的数据，包括结构化、半结构化和非结构化数据。
3. 数据湖中的数据是原始数据，是业务数据的完整副本。数据湖中的数据保持了他们在业务系统中原来的样子。
4.  数据湖需要具备完善的数据管理能力（完善的元数据），可以管理各类数据相关的要素，包括数据源、数据格式、连接信息、数据schema、权限管理等。
5. 数据湖需要具备多样化的分析能力，包括但不限于批处理、流式计算、交互式分析以及机器学习；同时，还需要提供一定的任务调度和管理能力。
6. 数据湖需要具备完善的数据生命周期管理能力。不光需要存储原始数据，还需要能够保存各类分析处理的中间结果，并完整的记录数据的分析处理过程，能帮助用户完整详细追溯任意一条数据的产生过程。
7. 数据湖需要具备完善的数据获取和数据发布能力。数据湖需要能支撑各种各样的数据源，并能从相关的数据源中获取全量/增量数据；然后规范存储。数据湖能将数据分析处理的结果推送到合适的存储引擎中，满足不同的应用访问需求。
8. 对于大数据的支持，包括超大规模存储以及可扩展的大规模数据处理能力。

---

![图片](http://img.wqkenqing.ren/typora_img/46a3408780793bb7e8f6605643dbef9a7196b4.png)

![图片](http://img.wqkenqing.ren/typora_img/f36d08f736a9c453bd22612a30c2da0a26a357-20240321170110839.png)

## 2、为什么是数据湖？

2.1 为什么命名为数据湖？

数据湖为什么叫数据湖而不叫数据河或者数据海？

```
“河”强调的是流动性，“海纳百川”，河终究是要流入大海的，而企业级数据是需要长期沉淀的，因此叫“湖”比叫“河”要贴切；同时，湖水天然是分层的，满足不同的生态系统要求，这与企业建设统一数据中心，存放管理数据的需求是一致的，“热”数据在上层，方便应用随时使用；温数据、冷数据位于数据中心不同的存储介质中，达到数据存储容量与成本的平衡。
不叫“海”的原因在于，海是无边无界的，而“湖”是有边界的，这个边界就是企业/组织的业务边界；因此数据湖需要更多的数据管理和权限管理能力。
叫“湖”的另一个重要原因是数据湖是需要精细治理的，一个缺乏管控、缺乏治理的数据湖最终会退化为“数据沼泽”，从而使应用无法有效访问数据，使存于其中的数据失去价值。
```



2.2 为什么会出现数据湖？

数据湖的发展阶段

第一阶段：以Hadoop为代表的离线数据处理基础设施

```
Hadoop是以HDFS为核心存储，以MapReduce（简称MR）为基本计算模型的批量数据处理基础设施。

围绕HDFS和MR，产生了一系列的组件，不断完善整个大数据平台的数据处理能力，例如面向在线KV操作的HBase、面向SQL的HIVE、面向工作流的PIG等。同时，随着大家对于批处理的性能要求越来越高，新的计算模型不断被提出，产生了Tez、Spark、Presto等计算引擎，MR模型也逐渐进化成DAG模型。
```

```
DAG模型一方面，增加计算模型的抽象并发能力：对每一个计算过程进行分解，根据计算过程中的聚合操作点对任务进行逻辑切分，任务被切分成一个个的stage，每个stage都可以有一个或者多个Task组成，Task是可以并发执行的，从而提升整个计算过程的并行能力；另一方面，为减少数据处理过程中的中间结果写文件操作，Spark、Presto等计算引擎尽量使用计算节点的内存对数据进行缓存，从而提高整个数据过程的效率和系统吞吐能力。
```

#### 第二阶段：Lambda架构

```
随着数据处理能力和处理需求的不断变化，越来越多的用户发现，批处理模式无论如何提升性能，也无法满足一些实时性要求高的处理场景，流式计算引擎应运而生，例如Storm、Spark Streaming、Flink等。

然而，随着越来越多的应用上线，大家发现，其实批处理和流计算配合使用，才能满足大部分应用需求；而对于用户而言，其实他们并不关心底层的计算模型是什么，用户希望无论是批处理还是流计算，都能基于统一的数据模型来返回处理结果，于是Lambda架构被提出.
Lambda架构的核心理念是“流批一体”，整个数据流向自左向右流入平台。进入平台后一分为二，一部分走批处理模式，一部分走流式计算模式。无论哪种计算模式，最终的处理结果都通过服务层对应用提供，确保访问的一致性。
```

#### 第三阶段：Kappa架构

Lambda架构解决了应用读取数据的一致性问题，但是“流批分离”的处理链路增大了研发的复杂性。因此，有人就提出能不能用一套系统来解决所有问题。目前比较流行的做法就是基于流计算来做。流计算天然的分布式特征，注定了他的扩展性更好。通过加大流计算的并发性，加大流式数据的“时间窗口”，来统一批处理与流式处理两种计算模式。

#### 第四阶段 数据湖





---

上述架构的反思，上述架构逐步解决了大数据的多维度处理能力，但数据的存储与利用上，又存在更多的差异化方案。这导致数据的应用与管理上又出现了许多不可控的点。在企业或团体中，大都在业务的发展中，又会针对这些问题点不约而同的进行一些的优化设计。并且，需要再优化设计的点也不尽相同。

于是数据湖这一概念也应运而生。

---

![CleanShot 2024-03-21 at 17.08.24@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2017.08.24@2x.png)

## 3、我们用哪款数据湖，为什么？

3.1  有哪些数据湖？

1、DeltaLake 2、Iceberg 3、hudi 



#### DeltaLake

Delta 时，希望做到流批作业在数据层面做到进一步的统一（如下图）。业务数据经过 Kafka 导入到统一的数据湖中（无论批处理，还是流处理），上层业务可以借助各种分析引擎做进一步的商业报表分析、流式计算以及 AI 分析等等。

![深度对比 Delta、Iceberg 和 Hudi 三大开源数据湖方案](http://img.wqkenqing.ren/typora_img/5ca7f0e25d90e130c9479963f9eceba7.png)

![CleanShot 2024-03-21 at 20.29.20@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2020.29.20@2x.png)

2、Iceberg

Iceberg是一种高性能的TableFormat(表格式),定义了数据、元数据的组织方式,支持在Spark、Trino、Flink、Hive及Impala等计算引擎中使用。

1. 真正的流批一体: 上游写入数据后下游立即可查,满足实时场景;Iceberg提供了流批读取和流批写入接口,用户可以在同一个流程同时处理流批数据,使得流批处理可以使用相同的存储模型,简化了ETL思路.
2. 支持异构计算和存储引擎: 存储上支持常见存储如HDFS以及各种对象存储(不与底层存储强绑定);计算上支持Flink,Spark,Presto,Hive等常见计算引擎.
   Schema Evolution(模式演化): 支持无副作用地增(ADD)删(Drop)改(Update)列,改变列顺序(Reorder)以及重命名列(Rename),且代价很低(只涉及元数据操作,不
3. 在数据重新读写操作)(Iceberg使用唯一ID定位列,新增列会分配新的ID,所以列不会错位)
4. Partition Evolution(分区演化): 在已有的表上改变分区策略时,之前的分区数据不会变且依然采用老的分区策略,新数据会采用新的分区策略.在Iceberg元数据里,两个分区策略相互独立.比如以前有个天分区表,现在业务需要小时分区,按Hive数仓的处理方式需要重新建表,但Iceberg表直接在原表上更改分区布局即可.
5. 支持隐藏分区: Iceberg的分区信息不需要人工维护,可以被隐藏起来.与Hive指定分区字段的方式不同,Iceberg的分区字段(分区策略)支持通过某字段计算出来,在建表或者修改分区策略之后, 新的数据会自动计算所属于的分区,查询时Iceberg会自动过滤不需要扫描的数据,避免了因用户SQL未指定分区过滤条件而导致的性能问题,让用户更专注业务逻辑而无需考虑分区字段过滤问题.(Iceberg分区信息和数据存储目录是相互独立开的,使得Iceberg表分区可以被修改,而且不涉及数据迁移;分区信息不存在HMS,减轻了HMS的压力) 
6. 分区演化和隐藏分区使得业务可以方便地调整分区策略.
7.  Time Travel: 可以查询历史某一时间点snapshot的数据,支持回滚到历史snapshot.
8.  支持事务(ACID): Iceberg提供了边读边写的能力,上游数据写入即可见,通过事务,保证了下游组件只能消费已经commit的数据,无法读到未提交的数据.支持添加删除更新数据. 
9. 支持基于乐观锁的并发写: Iceberg基于乐观锁提供了多个程序并发写入的能力并且保证数据线性一致.(乐观创建metadata文件,提交更新会触发metadata原子交换,完成提交) 
10. 文件级数据剪裁: Iceberg通过元数据来对查询进行高效过滤,Iceberg的元数据里面提供了每个数据文件的一些统计信息, 比如最大值, 最小值, Count计数等等. 因此, 查询SQL的过滤条件除了常规的分区, 列过滤, 甚至可以下推到文件级别, 大大加快了查询效率. 
11. 支持多种底层存储格式如Parquet、Avro以及ORC等. 
12. 支持Upsert能力,且更新即可见,但不能过于频繁,若Upsert过于频繁,则需要频繁数据合并

![alt](http://img.wqkenqing.ren/typora_img/Iceberg-2.png)

![CleanShot 2024-03-21 at 20.27.00@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2020.27.00@2x.png)

3、hudi

### Uber 和 Apache Hudi

Uber 的业务场景主要为：将线上产生的行程订单数据，同步到一个统一的数据中心，然后供上层各个城市运营同事用来做分析和处理。在 2014 年的时候，Uber 的数据湖架构相对比较简单，业务日志经由 Kafka 同步到 S3 上，上层用 EMR 做数据分析；线上的[关系型数据库](https://cloud.tencent.com/product/cdb-overview?from_column=20065&from=20065)以及 NoSQL 则会通过 ETL（ETL 任务也会拉去一些 Kakfa 同步到 S3 的数据）任务同步到闭源的 Vertica 分析型数据库，城市运营同学主要通过 Vertica SQL 实现数据聚合。当时也碰到数据格式混乱、系统扩展成本高（依赖收 Vertica 商业收费软件）、数据回填麻烦等问题。后续迁移到开源的 Hadoop 生态，解决了扩展性问题等问题，但依然碰到 Databricks 上述的一些问题，其中最核心的问题是无法快速 upsert 存量数据。

![深度对比 Delta、Iceberg 和 Hudi 三大开源数据湖方案](http://img.wqkenqing.ren/typora_img/75b5505d775d66642ace4413fa338cf2.png)

----



![CleanShot 2024-03-21 at 20.30.32@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2020.30.32@2x.png)

![CleanShot 2024-03-21 at 20.30.42@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2020.30.42@2x.png)

### Netflix 和 Apache Iceberg

![CleanShot 2024-03-21 at 20.31.23@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2020.31.23@2x.png)

![CleanShot 2024-03-21 at 20.31.30@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2020.31.30@2x.png)

![CleanShot 2024-03-21 at 20.32.15@2x](http://img.wqkenqing.ren/typora_img/CleanShot%202024-03-21%20at%2020.32.15@2x.png)



3.2 我们用哪几款数据湖？

1. 从上面我们可知，delta lake 相对更偏相于是Databricks公司出品的系列产品，为的是自家产品群的完善。深度绑定了spark等自家产品。于现有技术栈来讲，不适合。
2. hudi，hudi有着较大的现有环境的集成优势，它基于hdfs作为文件存储底座，在与我们现有的技术组件上的集成与运维管理上，有较大的优势。且它支持upsert与acid等多种性能优势。缺点就是它的功能较为丰富，但细节上不够丰富。如引擎上，官方对flink的支持不够好，当然已经集成的三方插件。
3. icerberg，icerberg相对来讲，在数据湖的设计底层实现上打磨的更好，且存储上支持对象存储。有更好的存储优势，但缺点就是要再独立运维一套，另外上层使用上相对薄弱

----

我个人建议，先从hudi切入，结合我们自身项目性质居多，可以从功能上做icerberg的接入尝试。

## 4、用数据湖能给我们带来什么？



## 5、未来展望？





---



